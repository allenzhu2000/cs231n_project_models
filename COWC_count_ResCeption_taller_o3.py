import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

__weights_dict = dict()

def load_weights(weight_file):
    if weight_file == None:
        return

    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()

    return weights_dict

class KitModel(nn.Module):

    
    def __init__(self, weight_file):
        super(KitModel, self).__init__()
        global __weights_dict
        __weights_dict = load_weights(weight_file)

        self.Layer1_7x7_Convolution_Stride_2 = self.__conv(2, name='Layer1_7x7/Convolution_Stride_2', in_channels=3, out_channels=64, kernel_size=(7, 7), stride=(2, 2), groups=1, bias=True)
        self.Layer1_7x7_BatchNorm_Stride_2 = self.__batch_normalization(2, 'Layer1_7x7/BatchNorm_Stride_2', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer2_3x3_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer2_3x3/Convolution_Inception3x3_reduce', in_channels=64, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer2_3x3_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer2_3x3/BatchNorm_Inception3x3_reduce', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer2_3x3_Convolution_Inception3x3 = self.__conv(2, name='Layer2_3x3/Convolution_Inception3x3', in_channels=64, out_channels=192, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer2_3x3_BatchNorm_Inception3x3 = self.__batch_normalization(2, 'Layer2_3x3/BatchNorm_Inception3x3', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3a_Convolution_ResCeption1x1 = self.__conv(2, name='Layer3a/Convolution_ResCeption1x1', in_channels=192, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3a_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer3a/Convolution_Inception3x3_reduce', in_channels=192, out_channels=96, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3a_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer3a/Convolution_Inception5x5_reduce', in_channels=192, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3a_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer3a/BatchNorm_Inception3x3_reduce', num_features=96, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3a_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer3a/BatchNorm_Inception5x5_reduce', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3a_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer3a/Convolution_Inception_Pool_1x1', in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3a_Convolution_Inception3x3 = self.__conv(2, name='Layer3a/Convolution_Inception3x3', in_channels=96, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer3a_Convolution_Inception5x5 = self.__conv(2, name='Layer3a/Convolution_Inception5x5', in_channels=16, out_channels=32, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer3a_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer3a/BatchNorm_EltWise', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3b_Convolution_ResCeption1x1 = self.__conv(2, name='Layer3b/Convolution_ResCeption1x1', in_channels=192, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3b_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer3b/Convolution_Inception3x3_reduce', in_channels=192, out_channels=96, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3b_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer3b/Convolution_Inception5x5_reduce', in_channels=192, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3b_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer3b/BatchNorm_Inception3x3_reduce', num_features=96, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3b_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer3b/BatchNorm_Inception5x5_reduce', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3b_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer3b/Convolution_Inception_Pool_1x1', in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3b_Convolution_Inception3x3 = self.__conv(2, name='Layer3b/Convolution_Inception3x3', in_channels=96, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer3b_Convolution_Inception5x5 = self.__conv(2, name='Layer3b/Convolution_Inception5x5', in_channels=16, out_channels=32, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer3b_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer3b/BatchNorm_EltWise', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3c_Convolution_ResCeption1x1 = self.__conv(2, name='Layer3c/Convolution_ResCeption1x1', in_channels=192, out_channels=352, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3c_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer3c/Convolution_Inception3x3_reduce', in_channels=192, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3c_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer3c/Convolution_Inception5x5_reduce', in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3c_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer3c/BatchNorm_Inception3x3_reduce', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3c_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer3c/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3c_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer3c/Convolution_Inception_Pool_1x1', in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3c_Convolution_Inception3x3 = self.__conv(2, name='Layer3c/Convolution_Inception3x3', in_channels=128, out_channels=192, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer3c_Convolution_Inception5x5 = self.__conv(2, name='Layer3c/Convolution_Inception5x5', in_channels=32, out_channels=96, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer3c_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer3c/BatchNorm_EltWise', num_features=352, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3d_Convolution_ResCeption1x1 = self.__conv(2, name='Layer3d/Convolution_ResCeption1x1', in_channels=352, out_channels=352, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3d_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer3d/Convolution_Inception3x3_reduce', in_channels=352, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3d_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer3d/Convolution_Inception5x5_reduce', in_channels=352, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3d_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer3d/BatchNorm_Inception3x3_reduce', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3d_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer3d/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer3d_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer3d/Convolution_Inception_Pool_1x1', in_channels=352, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer3d_Convolution_Inception3x3 = self.__conv(2, name='Layer3d/Convolution_Inception3x3', in_channels=128, out_channels=192, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer3d_Convolution_Inception5x5 = self.__conv(2, name='Layer3d/Convolution_Inception5x5', in_channels=32, out_channels=96, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer3d_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer3d/BatchNorm_EltWise', num_features=352, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4a_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4a/Convolution_ResCeption1x1', in_channels=352, out_channels=320, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4a_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4a/Convolution_Inception3x3_reduce', in_channels=352, out_channels=96, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4a_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4a/Convolution_Inception5x5_reduce', in_channels=352, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4a_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4a/BatchNorm_Inception3x3_reduce', num_features=96, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4a_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4a/BatchNorm_Inception5x5_reduce', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4a_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4a/Convolution_Inception_Pool_1x1', in_channels=352, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4a_Convolution_Inception3x3 = self.__conv(2, name='Layer4a/Convolution_Inception3x3', in_channels=96, out_channels=208, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4a_Convolution_Inception5x5 = self.__conv(2, name='Layer4a/Convolution_Inception5x5', in_channels=16, out_channels=48, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4a_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4a/BatchNorm_EltWise', num_features=320, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4b_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4b/Convolution_ResCeption1x1', in_channels=320, out_channels=320, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4b_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4b/Convolution_Inception3x3_reduce', in_channels=320, out_channels=96, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4b_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4b/Convolution_Inception5x5_reduce', in_channels=320, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4b_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4b/BatchNorm_Inception3x3_reduce', num_features=96, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4b_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4b/BatchNorm_Inception5x5_reduce', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4b_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4b/Convolution_Inception_Pool_1x1', in_channels=320, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4b_Convolution_Inception3x3 = self.__conv(2, name='Layer4b/Convolution_Inception3x3', in_channels=96, out_channels=208, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4b_Convolution_Inception5x5 = self.__conv(2, name='Layer4b/Convolution_Inception5x5', in_channels=16, out_channels=48, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4b_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4b/BatchNorm_EltWise', num_features=320, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4c_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4c/Convolution_ResCeption1x1', in_channels=320, out_channels=352, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4c_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4c/Convolution_Inception3x3_reduce', in_channels=320, out_channels=112, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4c_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4c/Convolution_Inception5x5_reduce', in_channels=320, out_channels=24, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Loss1_Convolution_Loss = self.__conv(2, name='Loss1/Convolution_Loss', in_channels=320, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4c_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4c/BatchNorm_Inception3x3_reduce', num_features=112, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4c_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4c/BatchNorm_Inception5x5_reduce', num_features=24, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4c_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4c/Convolution_Inception_Pool_1x1', in_channels=320, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Loss1_BatchNorm_Loss = self.__batch_normalization(2, 'Loss1/BatchNorm_Loss', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4c_Convolution_Inception3x3 = self.__conv(2, name='Layer4c/Convolution_Inception3x3', in_channels=112, out_channels=224, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4c_Convolution_Inception5x5 = self.__conv(2, name='Layer4c/Convolution_Inception5x5', in_channels=24, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Loss1_InnerProduct_Loss_fc1_1 = self.__dense(name = 'Loss1/InnerProduct_Loss_fc1_1', in_features = 2048, out_features = 1024, bias = True)
        self.Loss1_BatchNorm_Loss_fc1 = self.__batch_normalization(2, 'Loss1/BatchNorm_Loss_fc1', num_features=1024, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4c_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4c/BatchNorm_EltWise', num_features=352, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4d_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4d/Convolution_ResCeption1x1', in_channels=352, out_channels=352, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4d_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4d/Convolution_Inception3x3_reduce', in_channels=352, out_channels=112, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4d_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4d/Convolution_Inception5x5_reduce', in_channels=352, out_channels=24, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Loss1_InnerProduct_Loss_fc2_1 = self.__dense(name = 'Loss1/InnerProduct_Loss_fc2_1', in_features = 1024, out_features = 64, bias = True)
        self.Layer4d_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4d/BatchNorm_Inception3x3_reduce', num_features=112, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4d_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4d/BatchNorm_Inception5x5_reduce', num_features=24, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4d_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4d/Convolution_Inception_Pool_1x1', in_channels=352, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4d_Convolution_Inception3x3 = self.__conv(2, name='Layer4d/Convolution_Inception3x3', in_channels=112, out_channels=224, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4d_Convolution_Inception5x5 = self.__conv(2, name='Layer4d/Convolution_Inception5x5', in_channels=24, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4d_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4d/BatchNorm_EltWise', num_features=352, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4e_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4e/Convolution_ResCeption1x1', in_channels=352, out_channels=384, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4e_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4e/Convolution_Inception3x3_reduce', in_channels=352, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4e_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4e/Convolution_Inception5x5_reduce', in_channels=352, out_channels=24, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4e_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4e/BatchNorm_Inception3x3_reduce', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4e_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4e/BatchNorm_Inception5x5_reduce', num_features=24, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4e_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4e/Convolution_Inception_Pool_1x1', in_channels=352, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4e_Convolution_Inception3x3 = self.__conv(2, name='Layer4e/Convolution_Inception3x3', in_channels=128, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4e_Convolution_Inception5x5 = self.__conv(2, name='Layer4e/Convolution_Inception5x5', in_channels=24, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4e_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4e/BatchNorm_EltWise', num_features=384, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4f_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4f/Convolution_ResCeption1x1', in_channels=384, out_channels=384, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4f_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4f/Convolution_Inception3x3_reduce', in_channels=384, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4f_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4f/Convolution_Inception5x5_reduce', in_channels=384, out_channels=24, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4f_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4f/BatchNorm_Inception3x3_reduce', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4f_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4f/BatchNorm_Inception5x5_reduce', num_features=24, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4f_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4f/Convolution_Inception_Pool_1x1', in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4f_Convolution_Inception3x3 = self.__conv(2, name='Layer4f/Convolution_Inception3x3', in_channels=128, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4f_Convolution_Inception5x5 = self.__conv(2, name='Layer4f/Convolution_Inception5x5', in_channels=24, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4f_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4f/BatchNorm_EltWise', num_features=384, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4g_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4g/Convolution_ResCeption1x1', in_channels=384, out_channels=416, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4g_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4g/Convolution_Inception3x3_reduce', in_channels=384, out_channels=144, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4g_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4g/Convolution_Inception5x5_reduce', in_channels=384, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4g_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4g/BatchNorm_Inception3x3_reduce', num_features=144, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4g_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4g/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4g_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4g/Convolution_Inception_Pool_1x1', in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4g_Convolution_Inception3x3 = self.__conv(2, name='Layer4g/Convolution_Inception3x3', in_channels=144, out_channels=288, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4g_Convolution_Inception5x5 = self.__conv(2, name='Layer4g/Convolution_Inception5x5', in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4g_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4g/BatchNorm_EltWise', num_features=416, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4h_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4h/Convolution_ResCeption1x1', in_channels=416, out_channels=416, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4h_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4h/Convolution_Inception3x3_reduce', in_channels=416, out_channels=144, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4h_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4h/Convolution_Inception5x5_reduce', in_channels=416, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4h_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4h/BatchNorm_Inception3x3_reduce', num_features=144, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4h_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4h/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4h_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4h/Convolution_Inception_Pool_1x1', in_channels=416, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4h_Convolution_Inception3x3 = self.__conv(2, name='Layer4h/Convolution_Inception3x3', in_channels=144, out_channels=288, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4h_Convolution_Inception5x5 = self.__conv(2, name='Layer4h/Convolution_Inception5x5', in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4h_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4h/BatchNorm_EltWise', num_features=416, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4i_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4i/Convolution_ResCeption1x1', in_channels=416, out_channels=512, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4i_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4i/Convolution_Inception3x3_reduce', in_channels=416, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4i_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4i/Convolution_Inception5x5_reduce', in_channels=416, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Loss2_Convolution_Loss = self.__conv(2, name='Loss2/Convolution_Loss', in_channels=416, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4i_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4i/BatchNorm_Inception3x3_reduce', num_features=160, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4i_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4i/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4i_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4i/Convolution_Inception_Pool_1x1', in_channels=416, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Loss2_BatchNorm_Loss = self.__batch_normalization(2, 'Loss2/BatchNorm_Loss', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4i_Convolution_Inception3x3 = self.__conv(2, name='Layer4i/Convolution_Inception3x3', in_channels=160, out_channels=320, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4i_Convolution_Inception5x5 = self.__conv(2, name='Layer4i/Convolution_Inception5x5', in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Loss2_InnerProduct_Loss_fc1_1 = self.__dense(name = 'Loss2/InnerProduct_Loss_fc1_1', in_features = 2048, out_features = 1024, bias = True)
        self.Loss2_BatchNorm_Loss_fc1 = self.__batch_normalization(2, 'Loss2/BatchNorm_Loss_fc1', num_features=1024, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4i_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4i/BatchNorm_EltWise', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4j_Convolution_ResCeption1x1 = self.__conv(2, name='Layer4j/Convolution_ResCeption1x1', in_channels=512, out_channels=512, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4j_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer4j/Convolution_Inception3x3_reduce', in_channels=512, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4j_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer4j/Convolution_Inception5x5_reduce', in_channels=512, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Loss2_InnerProduct_Loss_fc2_1 = self.__dense(name = 'Loss2/InnerProduct_Loss_fc2_1', in_features = 1024, out_features = 64, bias = True)
        self.Layer4j_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer4j/BatchNorm_Inception3x3_reduce', num_features=160, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4j_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer4j/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer4j_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer4j/Convolution_Inception_Pool_1x1', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer4j_Convolution_Inception3x3 = self.__conv(2, name='Layer4j/Convolution_Inception3x3', in_channels=160, out_channels=320, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer4j_Convolution_Inception5x5 = self.__conv(2, name='Layer4j/Convolution_Inception5x5', in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer4j_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer4j/BatchNorm_EltWise', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5a_Convolution_ResCeption1x1 = self.__conv(2, name='Layer5a/Convolution_ResCeption1x1', in_channels=512, out_channels=576, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5a_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer5a/Convolution_Inception3x3_reduce', in_channels=512, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5a_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer5a/Convolution_Inception5x5_reduce', in_channels=512, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5a_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer5a/BatchNorm_Inception3x3_reduce', num_features=160, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5a_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer5a/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5a_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer5a/Convolution_Inception_Pool_1x1', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5a_Convolution_Inception3x3 = self.__conv(2, name='Layer5a/Convolution_Inception3x3', in_channels=160, out_channels=320, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer5a_Convolution_Inception5x5 = self.__conv(2, name='Layer5a/Convolution_Inception5x5', in_channels=32, out_channels=128, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer5a_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer5a/BatchNorm_EltWise', num_features=576, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5b_Convolution_ResCeption1x1 = self.__conv(2, name='Layer5b/Convolution_ResCeption1x1', in_channels=576, out_channels=576, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5b_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer5b/Convolution_Inception3x3_reduce', in_channels=576, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5b_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer5b/Convolution_Inception5x5_reduce', in_channels=576, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5b_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer5b/BatchNorm_Inception3x3_reduce', num_features=160, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5b_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer5b/BatchNorm_Inception5x5_reduce', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5b_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer5b/Convolution_Inception_Pool_1x1', in_channels=576, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5b_Convolution_Inception3x3 = self.__conv(2, name='Layer5b/Convolution_Inception3x3', in_channels=160, out_channels=320, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer5b_Convolution_Inception5x5 = self.__conv(2, name='Layer5b/Convolution_Inception5x5', in_channels=32, out_channels=128, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer5b_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer5b/BatchNorm_EltWise', num_features=576, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5c_Convolution_ResCeption1x1 = self.__conv(2, name='Layer5c/Convolution_ResCeption1x1', in_channels=576, out_channels=640, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5c_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer5c/Convolution_Inception3x3_reduce', in_channels=576, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5c_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer5c/Convolution_Inception5x5_reduce', in_channels=576, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5c_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer5c/BatchNorm_Inception3x3_reduce', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5c_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer5c/BatchNorm_Inception5x5_reduce', num_features=48, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5c_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer5c/Convolution_Inception_Pool_1x1', in_channels=576, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5c_Convolution_Inception3x3 = self.__conv(2, name='Layer5c/Convolution_Inception3x3', in_channels=192, out_channels=384, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer5c_Convolution_Inception5x5 = self.__conv(2, name='Layer5c/Convolution_Inception5x5', in_channels=48, out_channels=128, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer5c_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer5c/BatchNorm_EltWise', num_features=640, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5d_Convolution_ResCeption1x1 = self.__conv(2, name='Layer5d/Convolution_ResCeption1x1', in_channels=640, out_channels=640, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5d_Convolution_Inception3x3_reduce = self.__conv(2, name='Layer5d/Convolution_Inception3x3_reduce', in_channels=640, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5d_Convolution_Inception5x5_reduce = self.__conv(2, name='Layer5d/Convolution_Inception5x5_reduce', in_channels=640, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5d_BatchNorm_Inception3x3_reduce = self.__batch_normalization(2, 'Layer5d/BatchNorm_Inception3x3_reduce', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5d_BatchNorm_Inception5x5_reduce = self.__batch_normalization(2, 'Layer5d/BatchNorm_Inception5x5_reduce', num_features=48, eps=9.999999747378752e-06, momentum=0.0)
        self.Layer5d_Convolution_Inception_Pool_1x1 = self.__conv(2, name='Layer5d/Convolution_Inception_Pool_1x1', in_channels=640, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.Layer5d_Convolution_Inception3x3 = self.__conv(2, name='Layer5d/Convolution_Inception3x3', in_channels=192, out_channels=384, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=True)
        self.Layer5d_Convolution_Inception5x5 = self.__conv(2, name='Layer5d/Convolution_Inception5x5', in_channels=48, out_channels=128, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=True)
        self.Layer5d_BatchNorm_EltWise = self.__batch_normalization(2, 'Layer5d/BatchNorm_EltWise', num_features=640, eps=9.999999747378752e-06, momentum=0.0)
        self.Loss3_InnerProduct_Loss_fc1_1 = self.__dense(name = 'Loss3/InnerProduct_Loss_fc1_1', in_features = 640, out_features = 64, bias = True)

    def forward(self, x):
        Layer1_7x7_Convolution_Stride_2_pad = F.pad(x, (3, 3, 3, 3))
        Layer1_7x7_Convolution_Stride_2 = self.Layer1_7x7_Convolution_Stride_2(Layer1_7x7_Convolution_Stride_2_pad)
        Layer1_7x7_BatchNorm_Stride_2 = self.Layer1_7x7_BatchNorm_Stride_2(Layer1_7x7_Convolution_Stride_2)
        Layer1_7x7_ReLU_Stride_2 = F.relu(Layer1_7x7_BatchNorm_Stride_2)
        Layer1_Pooling_Pooling_Stride_2_pad = F.pad(Layer1_7x7_ReLU_Stride_2, (0, 1, 0, 1), value=float('-inf'))
        Layer1_Pooling_Pooling_Stride_2 = F.max_pool2d(Layer1_Pooling_Pooling_Stride_2_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False)
        Layer2_3x3_Convolution_Inception3x3_reduce = self.Layer2_3x3_Convolution_Inception3x3_reduce(Layer1_Pooling_Pooling_Stride_2)
        Layer2_3x3_BatchNorm_Inception3x3_reduce = self.Layer2_3x3_BatchNorm_Inception3x3_reduce(Layer2_3x3_Convolution_Inception3x3_reduce)
        Layer2_3x3_ReLU_Inception3x3_reduce = F.relu(Layer2_3x3_BatchNorm_Inception3x3_reduce)
        Layer2_3x3_Convolution_Inception3x3_pad = F.pad(Layer2_3x3_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer2_3x3_Convolution_Inception3x3 = self.Layer2_3x3_Convolution_Inception3x3(Layer2_3x3_Convolution_Inception3x3_pad)
        Layer2_3x3_BatchNorm_Inception3x3 = self.Layer2_3x3_BatchNorm_Inception3x3(Layer2_3x3_Convolution_Inception3x3)
        Layer2_3x3_ReLU_Inception3x3 = F.relu(Layer2_3x3_BatchNorm_Inception3x3)
        Layer2_Pooling_Pooling_Stride_2_pad = F.pad(Layer2_3x3_ReLU_Inception3x3, (0, 1, 0, 1), value=float('-inf'))
        Layer2_Pooling_Pooling_Stride_2 = F.max_pool2d(Layer2_Pooling_Pooling_Stride_2_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False)
        Layer3a_Convolution_ResCeption1x1 = self.Layer3a_Convolution_ResCeption1x1(Layer2_Pooling_Pooling_Stride_2)
        Layer3a_Convolution_Inception3x3_reduce = self.Layer3a_Convolution_Inception3x3_reduce(Layer2_Pooling_Pooling_Stride_2)
        Layer3a_Convolution_Inception5x5_reduce = self.Layer3a_Convolution_Inception5x5_reduce(Layer2_Pooling_Pooling_Stride_2)
        Layer3a_Pooling_Inception_Pool_pad = F.pad(Layer2_Pooling_Pooling_Stride_2, (1, 1, 1, 1), value=float('-inf'))
        Layer3a_Pooling_Inception_Pool = F.max_pool2d(Layer3a_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer3a_BatchNorm_Inception3x3_reduce = self.Layer3a_BatchNorm_Inception3x3_reduce(Layer3a_Convolution_Inception3x3_reduce)
        Layer3a_BatchNorm_Inception5x5_reduce = self.Layer3a_BatchNorm_Inception5x5_reduce(Layer3a_Convolution_Inception5x5_reduce)
        Layer3a_Convolution_Inception_Pool_1x1 = self.Layer3a_Convolution_Inception_Pool_1x1(Layer3a_Pooling_Inception_Pool)
        Layer3a_ReLU_Inception3x3_reduce = F.relu(Layer3a_BatchNorm_Inception3x3_reduce)
        Layer3a_ReLU_Inception5x5_reduce = F.relu(Layer3a_BatchNorm_Inception5x5_reduce)
        Layer3a_Convolution_Inception3x3_pad = F.pad(Layer3a_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer3a_Convolution_Inception3x3 = self.Layer3a_Convolution_Inception3x3(Layer3a_Convolution_Inception3x3_pad)
        Layer3a_Convolution_Inception5x5_pad = F.pad(Layer3a_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer3a_Convolution_Inception5x5 = self.Layer3a_Convolution_Inception5x5(Layer3a_Convolution_Inception5x5_pad)
        Layer3a_Concat_Output = torch.cat((Layer3a_Convolution_Inception3x3, Layer3a_Convolution_Inception5x5, Layer3a_Convolution_Inception_Pool_1x1), 1)
        Layer3a_Eltwise_EltWise = Layer3a_Concat_Output + Layer3a_Convolution_ResCeption1x1
        Layer3a_BatchNorm_EltWise = self.Layer3a_BatchNorm_EltWise(Layer3a_Eltwise_EltWise)
        Layer3a_ReLU_EltWise = F.relu(Layer3a_BatchNorm_EltWise)
        Layer3b_Convolution_ResCeption1x1 = self.Layer3b_Convolution_ResCeption1x1(Layer3a_ReLU_EltWise)
        Layer3b_Convolution_Inception3x3_reduce = self.Layer3b_Convolution_Inception3x3_reduce(Layer3a_ReLU_EltWise)
        Layer3b_Convolution_Inception5x5_reduce = self.Layer3b_Convolution_Inception5x5_reduce(Layer3a_ReLU_EltWise)
        Layer3b_Pooling_Inception_Pool_pad = F.pad(Layer3a_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer3b_Pooling_Inception_Pool = F.max_pool2d(Layer3b_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer3b_BatchNorm_Inception3x3_reduce = self.Layer3b_BatchNorm_Inception3x3_reduce(Layer3b_Convolution_Inception3x3_reduce)
        Layer3b_BatchNorm_Inception5x5_reduce = self.Layer3b_BatchNorm_Inception5x5_reduce(Layer3b_Convolution_Inception5x5_reduce)
        Layer3b_Convolution_Inception_Pool_1x1 = self.Layer3b_Convolution_Inception_Pool_1x1(Layer3b_Pooling_Inception_Pool)
        Layer3b_ReLU_Inception3x3_reduce = F.relu(Layer3b_BatchNorm_Inception3x3_reduce)
        Layer3b_ReLU_Inception5x5_reduce = F.relu(Layer3b_BatchNorm_Inception5x5_reduce)
        Layer3b_Convolution_Inception3x3_pad = F.pad(Layer3b_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer3b_Convolution_Inception3x3 = self.Layer3b_Convolution_Inception3x3(Layer3b_Convolution_Inception3x3_pad)
        Layer3b_Convolution_Inception5x5_pad = F.pad(Layer3b_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer3b_Convolution_Inception5x5 = self.Layer3b_Convolution_Inception5x5(Layer3b_Convolution_Inception5x5_pad)
        Layer3b_Concat_Output = torch.cat((Layer3b_Convolution_Inception3x3, Layer3b_Convolution_Inception5x5, Layer3b_Convolution_Inception_Pool_1x1), 1)
        Layer3b_Eltwise_EltWise = Layer3b_Concat_Output + Layer3b_Convolution_ResCeption1x1
        Layer3b_BatchNorm_EltWise = self.Layer3b_BatchNorm_EltWise(Layer3b_Eltwise_EltWise)
        Layer3b_ReLU_EltWise = F.relu(Layer3b_BatchNorm_EltWise)
        Layer3c_Convolution_ResCeption1x1 = self.Layer3c_Convolution_ResCeption1x1(Layer3b_ReLU_EltWise)
        Layer3c_Convolution_Inception3x3_reduce = self.Layer3c_Convolution_Inception3x3_reduce(Layer3b_ReLU_EltWise)
        Layer3c_Convolution_Inception5x5_reduce = self.Layer3c_Convolution_Inception5x5_reduce(Layer3b_ReLU_EltWise)
        Layer3c_Pooling_Inception_Pool_pad = F.pad(Layer3b_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer3c_Pooling_Inception_Pool = F.max_pool2d(Layer3c_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer3c_BatchNorm_Inception3x3_reduce = self.Layer3c_BatchNorm_Inception3x3_reduce(Layer3c_Convolution_Inception3x3_reduce)
        Layer3c_BatchNorm_Inception5x5_reduce = self.Layer3c_BatchNorm_Inception5x5_reduce(Layer3c_Convolution_Inception5x5_reduce)
        Layer3c_Convolution_Inception_Pool_1x1 = self.Layer3c_Convolution_Inception_Pool_1x1(Layer3c_Pooling_Inception_Pool)
        Layer3c_ReLU_Inception3x3_reduce = F.relu(Layer3c_BatchNorm_Inception3x3_reduce)
        Layer3c_ReLU_Inception5x5_reduce = F.relu(Layer3c_BatchNorm_Inception5x5_reduce)
        Layer3c_Convolution_Inception3x3_pad = F.pad(Layer3c_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer3c_Convolution_Inception3x3 = self.Layer3c_Convolution_Inception3x3(Layer3c_Convolution_Inception3x3_pad)
        Layer3c_Convolution_Inception5x5_pad = F.pad(Layer3c_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer3c_Convolution_Inception5x5 = self.Layer3c_Convolution_Inception5x5(Layer3c_Convolution_Inception5x5_pad)
        Layer3c_Concat_Output = torch.cat((Layer3c_Convolution_Inception3x3, Layer3c_Convolution_Inception5x5, Layer3c_Convolution_Inception_Pool_1x1), 1)
        Layer3c_Eltwise_EltWise = Layer3c_Concat_Output + Layer3c_Convolution_ResCeption1x1
        Layer3c_BatchNorm_EltWise = self.Layer3c_BatchNorm_EltWise(Layer3c_Eltwise_EltWise)
        Layer3c_ReLU_EltWise = F.relu(Layer3c_BatchNorm_EltWise)
        Layer3d_Convolution_ResCeption1x1 = self.Layer3d_Convolution_ResCeption1x1(Layer3c_ReLU_EltWise)
        Layer3d_Convolution_Inception3x3_reduce = self.Layer3d_Convolution_Inception3x3_reduce(Layer3c_ReLU_EltWise)
        Layer3d_Convolution_Inception5x5_reduce = self.Layer3d_Convolution_Inception5x5_reduce(Layer3c_ReLU_EltWise)
        Layer3d_Pooling_Inception_Pool_pad = F.pad(Layer3c_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer3d_Pooling_Inception_Pool = F.max_pool2d(Layer3d_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer3d_BatchNorm_Inception3x3_reduce = self.Layer3d_BatchNorm_Inception3x3_reduce(Layer3d_Convolution_Inception3x3_reduce)
        Layer3d_BatchNorm_Inception5x5_reduce = self.Layer3d_BatchNorm_Inception5x5_reduce(Layer3d_Convolution_Inception5x5_reduce)
        Layer3d_Convolution_Inception_Pool_1x1 = self.Layer3d_Convolution_Inception_Pool_1x1(Layer3d_Pooling_Inception_Pool)
        Layer3d_ReLU_Inception3x3_reduce = F.relu(Layer3d_BatchNorm_Inception3x3_reduce)
        Layer3d_ReLU_Inception5x5_reduce = F.relu(Layer3d_BatchNorm_Inception5x5_reduce)
        Layer3d_Convolution_Inception3x3_pad = F.pad(Layer3d_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer3d_Convolution_Inception3x3 = self.Layer3d_Convolution_Inception3x3(Layer3d_Convolution_Inception3x3_pad)
        Layer3d_Convolution_Inception5x5_pad = F.pad(Layer3d_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer3d_Convolution_Inception5x5 = self.Layer3d_Convolution_Inception5x5(Layer3d_Convolution_Inception5x5_pad)
        Layer3d_Concat_Output = torch.cat((Layer3d_Convolution_Inception3x3, Layer3d_Convolution_Inception5x5, Layer3d_Convolution_Inception_Pool_1x1), 1)
        Layer3d_Eltwise_EltWise = Layer3d_Concat_Output + Layer3d_Convolution_ResCeption1x1
        Layer3d_BatchNorm_EltWise = self.Layer3d_BatchNorm_EltWise(Layer3d_Eltwise_EltWise)
        Layer3d_ReLU_EltWise = F.relu(Layer3d_BatchNorm_EltWise)
        Layer3_Pooling_Pooling_Stride_2_pad = F.pad(Layer3d_ReLU_EltWise, (0, 1, 0, 1), value=float('-inf'))
        Layer3_Pooling_Pooling_Stride_2 = F.max_pool2d(Layer3_Pooling_Pooling_Stride_2_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False)
        Layer4a_Convolution_ResCeption1x1 = self.Layer4a_Convolution_ResCeption1x1(Layer3_Pooling_Pooling_Stride_2)
        Layer4a_Convolution_Inception3x3_reduce = self.Layer4a_Convolution_Inception3x3_reduce(Layer3_Pooling_Pooling_Stride_2)
        Layer4a_Convolution_Inception5x5_reduce = self.Layer4a_Convolution_Inception5x5_reduce(Layer3_Pooling_Pooling_Stride_2)
        Layer4a_Pooling_Inception_Pool_pad = F.pad(Layer3_Pooling_Pooling_Stride_2, (1, 1, 1, 1), value=float('-inf'))
        Layer4a_Pooling_Inception_Pool = F.max_pool2d(Layer4a_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer4a_BatchNorm_Inception3x3_reduce = self.Layer4a_BatchNorm_Inception3x3_reduce(Layer4a_Convolution_Inception3x3_reduce)
        Layer4a_BatchNorm_Inception5x5_reduce = self.Layer4a_BatchNorm_Inception5x5_reduce(Layer4a_Convolution_Inception5x5_reduce)
        Layer4a_Convolution_Inception_Pool_1x1 = self.Layer4a_Convolution_Inception_Pool_1x1(Layer4a_Pooling_Inception_Pool)
        Layer4a_ReLU_Inception3x3_reduce = F.relu(Layer4a_BatchNorm_Inception3x3_reduce)
        Layer4a_ReLU_Inception5x5_reduce = F.relu(Layer4a_BatchNorm_Inception5x5_reduce)
        Layer4a_Convolution_Inception3x3_pad = F.pad(Layer4a_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4a_Convolution_Inception3x3 = self.Layer4a_Convolution_Inception3x3(Layer4a_Convolution_Inception3x3_pad)
        Layer4a_Convolution_Inception5x5_pad = F.pad(Layer4a_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4a_Convolution_Inception5x5 = self.Layer4a_Convolution_Inception5x5(Layer4a_Convolution_Inception5x5_pad)
        Layer4a_Concat_Output = torch.cat((Layer4a_Convolution_Inception3x3, Layer4a_Convolution_Inception5x5, Layer4a_Convolution_Inception_Pool_1x1), 1)
        Layer4a_Eltwise_EltWise = Layer4a_Concat_Output + Layer4a_Convolution_ResCeption1x1
        Layer4a_BatchNorm_EltWise = self.Layer4a_BatchNorm_EltWise(Layer4a_Eltwise_EltWise)
        Layer4a_ReLU_EltWise = F.relu(Layer4a_BatchNorm_EltWise)
        Layer4b_Convolution_ResCeption1x1 = self.Layer4b_Convolution_ResCeption1x1(Layer4a_ReLU_EltWise)
        Layer4b_Convolution_Inception3x3_reduce = self.Layer4b_Convolution_Inception3x3_reduce(Layer4a_ReLU_EltWise)
        Layer4b_Convolution_Inception5x5_reduce = self.Layer4b_Convolution_Inception5x5_reduce(Layer4a_ReLU_EltWise)
        Layer4b_Pooling_Inception_Pool_pad = F.pad(Layer4a_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4b_Pooling_Inception_Pool = F.max_pool2d(Layer4b_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer4b_BatchNorm_Inception3x3_reduce = self.Layer4b_BatchNorm_Inception3x3_reduce(Layer4b_Convolution_Inception3x3_reduce)
        Layer4b_BatchNorm_Inception5x5_reduce = self.Layer4b_BatchNorm_Inception5x5_reduce(Layer4b_Convolution_Inception5x5_reduce)
        Layer4b_Convolution_Inception_Pool_1x1 = self.Layer4b_Convolution_Inception_Pool_1x1(Layer4b_Pooling_Inception_Pool)
        Layer4b_ReLU_Inception3x3_reduce = F.relu(Layer4b_BatchNorm_Inception3x3_reduce)
        Layer4b_ReLU_Inception5x5_reduce = F.relu(Layer4b_BatchNorm_Inception5x5_reduce)
        Layer4b_Convolution_Inception3x3_pad = F.pad(Layer4b_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4b_Convolution_Inception3x3 = self.Layer4b_Convolution_Inception3x3(Layer4b_Convolution_Inception3x3_pad)
        Layer4b_Convolution_Inception5x5_pad = F.pad(Layer4b_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4b_Convolution_Inception5x5 = self.Layer4b_Convolution_Inception5x5(Layer4b_Convolution_Inception5x5_pad)
        Layer4b_Concat_Output = torch.cat((Layer4b_Convolution_Inception3x3, Layer4b_Convolution_Inception5x5, Layer4b_Convolution_Inception_Pool_1x1), 1)
        Layer4b_Eltwise_EltWise = Layer4b_Concat_Output + Layer4b_Convolution_ResCeption1x1
        Layer4b_BatchNorm_EltWise = self.Layer4b_BatchNorm_EltWise(Layer4b_Eltwise_EltWise)
        Layer4b_ReLU_EltWise = F.relu(Layer4b_BatchNorm_EltWise)
        Loss1_Pooling_Loss = F.avg_pool2d(Layer4b_ReLU_EltWise, kernel_size=(5, 5), stride=(3, 3), padding=(0,), ceil_mode=True, count_include_pad=False)
        Layer4c_Convolution_ResCeption1x1 = self.Layer4c_Convolution_ResCeption1x1(Layer4b_ReLU_EltWise)
        Layer4c_Convolution_Inception3x3_reduce = self.Layer4c_Convolution_Inception3x3_reduce(Layer4b_ReLU_EltWise)
        Layer4c_Convolution_Inception5x5_reduce = self.Layer4c_Convolution_Inception5x5_reduce(Layer4b_ReLU_EltWise)
        Layer4c_Pooling_Inception_Pool_pad = F.pad(Layer4b_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4c_Pooling_Inception_Pool = F.max_pool2d(Layer4c_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Loss1_Convolution_Loss = self.Loss1_Convolution_Loss(Loss1_Pooling_Loss)
        Layer4c_BatchNorm_Inception3x3_reduce = self.Layer4c_BatchNorm_Inception3x3_reduce(Layer4c_Convolution_Inception3x3_reduce)
        Layer4c_BatchNorm_Inception5x5_reduce = self.Layer4c_BatchNorm_Inception5x5_reduce(Layer4c_Convolution_Inception5x5_reduce)
        Layer4c_Convolution_Inception_Pool_1x1 = self.Layer4c_Convolution_Inception_Pool_1x1(Layer4c_Pooling_Inception_Pool)
        Loss1_BatchNorm_Loss = self.Loss1_BatchNorm_Loss(Loss1_Convolution_Loss)
        Layer4c_ReLU_Inception3x3_reduce = F.relu(Layer4c_BatchNorm_Inception3x3_reduce)
        Layer4c_ReLU_Inception5x5_reduce = F.relu(Layer4c_BatchNorm_Inception5x5_reduce)
        Loss1_ReLU_Loss = F.relu(Loss1_BatchNorm_Loss)
        Layer4c_Convolution_Inception3x3_pad = F.pad(Layer4c_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4c_Convolution_Inception3x3 = self.Layer4c_Convolution_Inception3x3(Layer4c_Convolution_Inception3x3_pad)
        Layer4c_Convolution_Inception5x5_pad = F.pad(Layer4c_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4c_Convolution_Inception5x5 = self.Layer4c_Convolution_Inception5x5(Layer4c_Convolution_Inception5x5_pad)
        Loss1_InnerProduct_Loss_fc1_0 = Loss1_ReLU_Loss.view(Loss1_ReLU_Loss.size(0), -1)
        Layer4c_Concat_Output = torch.cat((Layer4c_Convolution_Inception3x3, Layer4c_Convolution_Inception5x5, Layer4c_Convolution_Inception_Pool_1x1), 1)
        Loss1_InnerProduct_Loss_fc1_1 = self.Loss1_InnerProduct_Loss_fc1_1(Loss1_InnerProduct_Loss_fc1_0)
        Layer4c_Eltwise_EltWise = Layer4c_Concat_Output + Layer4c_Convolution_ResCeption1x1
        Loss1_BatchNorm_Loss_fc1 = self.Loss1_BatchNorm_Loss_fc1(Loss1_InnerProduct_Loss_fc1_1)
        Layer4c_BatchNorm_EltWise = self.Layer4c_BatchNorm_EltWise(Layer4c_Eltwise_EltWise)
        Loss1_ReLU_Loss_fc1 = F.relu(Loss1_BatchNorm_Loss_fc1)
        Layer4c_ReLU_EltWise = F.relu(Layer4c_BatchNorm_EltWise)
        Loss1_InnerProduct_Loss_fc2_0 = Loss1_ReLU_Loss_fc1.view(Loss1_ReLU_Loss_fc1.size(0), -1)
        Layer4d_Convolution_ResCeption1x1 = self.Layer4d_Convolution_ResCeption1x1(Layer4c_ReLU_EltWise)
        Layer4d_Convolution_Inception3x3_reduce = self.Layer4d_Convolution_Inception3x3_reduce(Layer4c_ReLU_EltWise)
        Layer4d_Convolution_Inception5x5_reduce = self.Layer4d_Convolution_Inception5x5_reduce(Layer4c_ReLU_EltWise)
        Layer4d_Pooling_Inception_Pool_pad = F.pad(Layer4c_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4d_Pooling_Inception_Pool = F.max_pool2d(Layer4d_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Loss1_InnerProduct_Loss_fc2_1 = self.Loss1_InnerProduct_Loss_fc2_1(Loss1_InnerProduct_Loss_fc2_0)
        Layer4d_BatchNorm_Inception3x3_reduce = self.Layer4d_BatchNorm_Inception3x3_reduce(Layer4d_Convolution_Inception3x3_reduce)
        Layer4d_BatchNorm_Inception5x5_reduce = self.Layer4d_BatchNorm_Inception5x5_reduce(Layer4d_Convolution_Inception5x5_reduce)
        Layer4d_Convolution_Inception_Pool_1x1 = self.Layer4d_Convolution_Inception_Pool_1x1(Layer4d_Pooling_Inception_Pool)
        Layer4d_ReLU_Inception3x3_reduce = F.relu(Layer4d_BatchNorm_Inception3x3_reduce)
        Layer4d_ReLU_Inception5x5_reduce = F.relu(Layer4d_BatchNorm_Inception5x5_reduce)
        Layer4d_Convolution_Inception3x3_pad = F.pad(Layer4d_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4d_Convolution_Inception3x3 = self.Layer4d_Convolution_Inception3x3(Layer4d_Convolution_Inception3x3_pad)
        Layer4d_Convolution_Inception5x5_pad = F.pad(Layer4d_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4d_Convolution_Inception5x5 = self.Layer4d_Convolution_Inception5x5(Layer4d_Convolution_Inception5x5_pad)
        Layer4d_Concat_Output = torch.cat((Layer4d_Convolution_Inception3x3, Layer4d_Convolution_Inception5x5, Layer4d_Convolution_Inception_Pool_1x1), 1)
        Layer4d_Eltwise_EltWise = Layer4d_Concat_Output + Layer4d_Convolution_ResCeption1x1
        Layer4d_BatchNorm_EltWise = self.Layer4d_BatchNorm_EltWise(Layer4d_Eltwise_EltWise)
        Layer4d_ReLU_EltWise = F.relu(Layer4d_BatchNorm_EltWise)
        Layer4e_Convolution_ResCeption1x1 = self.Layer4e_Convolution_ResCeption1x1(Layer4d_ReLU_EltWise)
        Layer4e_Convolution_Inception3x3_reduce = self.Layer4e_Convolution_Inception3x3_reduce(Layer4d_ReLU_EltWise)
        Layer4e_Convolution_Inception5x5_reduce = self.Layer4e_Convolution_Inception5x5_reduce(Layer4d_ReLU_EltWise)
        Layer4e_Pooling_Inception_Pool_pad = F.pad(Layer4d_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4e_Pooling_Inception_Pool = F.max_pool2d(Layer4e_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer4e_BatchNorm_Inception3x3_reduce = self.Layer4e_BatchNorm_Inception3x3_reduce(Layer4e_Convolution_Inception3x3_reduce)
        Layer4e_BatchNorm_Inception5x5_reduce = self.Layer4e_BatchNorm_Inception5x5_reduce(Layer4e_Convolution_Inception5x5_reduce)
        Layer4e_Convolution_Inception_Pool_1x1 = self.Layer4e_Convolution_Inception_Pool_1x1(Layer4e_Pooling_Inception_Pool)
        Layer4e_ReLU_Inception3x3_reduce = F.relu(Layer4e_BatchNorm_Inception3x3_reduce)
        Layer4e_ReLU_Inception5x5_reduce = F.relu(Layer4e_BatchNorm_Inception5x5_reduce)
        Layer4e_Convolution_Inception3x3_pad = F.pad(Layer4e_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4e_Convolution_Inception3x3 = self.Layer4e_Convolution_Inception3x3(Layer4e_Convolution_Inception3x3_pad)
        Layer4e_Convolution_Inception5x5_pad = F.pad(Layer4e_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4e_Convolution_Inception5x5 = self.Layer4e_Convolution_Inception5x5(Layer4e_Convolution_Inception5x5_pad)
        Layer4e_Concat_Output = torch.cat((Layer4e_Convolution_Inception3x3, Layer4e_Convolution_Inception5x5, Layer4e_Convolution_Inception_Pool_1x1), 1)
        Layer4e_Eltwise_EltWise = Layer4e_Concat_Output + Layer4e_Convolution_ResCeption1x1
        Layer4e_BatchNorm_EltWise = self.Layer4e_BatchNorm_EltWise(Layer4e_Eltwise_EltWise)
        Layer4e_ReLU_EltWise = F.relu(Layer4e_BatchNorm_EltWise)
        Layer4f_Convolution_ResCeption1x1 = self.Layer4f_Convolution_ResCeption1x1(Layer4e_ReLU_EltWise)
        Layer4f_Convolution_Inception3x3_reduce = self.Layer4f_Convolution_Inception3x3_reduce(Layer4e_ReLU_EltWise)
        Layer4f_Convolution_Inception5x5_reduce = self.Layer4f_Convolution_Inception5x5_reduce(Layer4e_ReLU_EltWise)
        Layer4f_Pooling_Inception_Pool_pad = F.pad(Layer4e_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4f_Pooling_Inception_Pool = F.max_pool2d(Layer4f_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer4f_BatchNorm_Inception3x3_reduce = self.Layer4f_BatchNorm_Inception3x3_reduce(Layer4f_Convolution_Inception3x3_reduce)
        Layer4f_BatchNorm_Inception5x5_reduce = self.Layer4f_BatchNorm_Inception5x5_reduce(Layer4f_Convolution_Inception5x5_reduce)
        Layer4f_Convolution_Inception_Pool_1x1 = self.Layer4f_Convolution_Inception_Pool_1x1(Layer4f_Pooling_Inception_Pool)
        Layer4f_ReLU_Inception3x3_reduce = F.relu(Layer4f_BatchNorm_Inception3x3_reduce)
        Layer4f_ReLU_Inception5x5_reduce = F.relu(Layer4f_BatchNorm_Inception5x5_reduce)
        Layer4f_Convolution_Inception3x3_pad = F.pad(Layer4f_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4f_Convolution_Inception3x3 = self.Layer4f_Convolution_Inception3x3(Layer4f_Convolution_Inception3x3_pad)
        Layer4f_Convolution_Inception5x5_pad = F.pad(Layer4f_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4f_Convolution_Inception5x5 = self.Layer4f_Convolution_Inception5x5(Layer4f_Convolution_Inception5x5_pad)
        Layer4f_Concat_Output = torch.cat((Layer4f_Convolution_Inception3x3, Layer4f_Convolution_Inception5x5, Layer4f_Convolution_Inception_Pool_1x1), 1)
        Layer4f_Eltwise_EltWise = Layer4f_Concat_Output + Layer4f_Convolution_ResCeption1x1
        Layer4f_BatchNorm_EltWise = self.Layer4f_BatchNorm_EltWise(Layer4f_Eltwise_EltWise)
        Layer4f_ReLU_EltWise = F.relu(Layer4f_BatchNorm_EltWise)
        Layer4g_Convolution_ResCeption1x1 = self.Layer4g_Convolution_ResCeption1x1(Layer4f_ReLU_EltWise)
        Layer4g_Convolution_Inception3x3_reduce = self.Layer4g_Convolution_Inception3x3_reduce(Layer4f_ReLU_EltWise)
        Layer4g_Convolution_Inception5x5_reduce = self.Layer4g_Convolution_Inception5x5_reduce(Layer4f_ReLU_EltWise)
        Layer4g_Pooling_Inception_Pool_pad = F.pad(Layer4f_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4g_Pooling_Inception_Pool = F.max_pool2d(Layer4g_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer4g_BatchNorm_Inception3x3_reduce = self.Layer4g_BatchNorm_Inception3x3_reduce(Layer4g_Convolution_Inception3x3_reduce)
        Layer4g_BatchNorm_Inception5x5_reduce = self.Layer4g_BatchNorm_Inception5x5_reduce(Layer4g_Convolution_Inception5x5_reduce)
        Layer4g_Convolution_Inception_Pool_1x1 = self.Layer4g_Convolution_Inception_Pool_1x1(Layer4g_Pooling_Inception_Pool)
        Layer4g_ReLU_Inception3x3_reduce = F.relu(Layer4g_BatchNorm_Inception3x3_reduce)
        Layer4g_ReLU_Inception5x5_reduce = F.relu(Layer4g_BatchNorm_Inception5x5_reduce)
        Layer4g_Convolution_Inception3x3_pad = F.pad(Layer4g_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4g_Convolution_Inception3x3 = self.Layer4g_Convolution_Inception3x3(Layer4g_Convolution_Inception3x3_pad)
        Layer4g_Convolution_Inception5x5_pad = F.pad(Layer4g_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4g_Convolution_Inception5x5 = self.Layer4g_Convolution_Inception5x5(Layer4g_Convolution_Inception5x5_pad)
        Layer4g_Concat_Output = torch.cat((Layer4g_Convolution_Inception3x3, Layer4g_Convolution_Inception5x5, Layer4g_Convolution_Inception_Pool_1x1), 1)
        Layer4g_Eltwise_EltWise = Layer4g_Concat_Output + Layer4g_Convolution_ResCeption1x1
        Layer4g_BatchNorm_EltWise = self.Layer4g_BatchNorm_EltWise(Layer4g_Eltwise_EltWise)
        Layer4g_ReLU_EltWise = F.relu(Layer4g_BatchNorm_EltWise)
        Layer4h_Convolution_ResCeption1x1 = self.Layer4h_Convolution_ResCeption1x1(Layer4g_ReLU_EltWise)
        Layer4h_Convolution_Inception3x3_reduce = self.Layer4h_Convolution_Inception3x3_reduce(Layer4g_ReLU_EltWise)
        Layer4h_Convolution_Inception5x5_reduce = self.Layer4h_Convolution_Inception5x5_reduce(Layer4g_ReLU_EltWise)
        Layer4h_Pooling_Inception_Pool_pad = F.pad(Layer4g_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4h_Pooling_Inception_Pool = F.max_pool2d(Layer4h_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer4h_BatchNorm_Inception3x3_reduce = self.Layer4h_BatchNorm_Inception3x3_reduce(Layer4h_Convolution_Inception3x3_reduce)
        Layer4h_BatchNorm_Inception5x5_reduce = self.Layer4h_BatchNorm_Inception5x5_reduce(Layer4h_Convolution_Inception5x5_reduce)
        Layer4h_Convolution_Inception_Pool_1x1 = self.Layer4h_Convolution_Inception_Pool_1x1(Layer4h_Pooling_Inception_Pool)
        Layer4h_ReLU_Inception3x3_reduce = F.relu(Layer4h_BatchNorm_Inception3x3_reduce)
        Layer4h_ReLU_Inception5x5_reduce = F.relu(Layer4h_BatchNorm_Inception5x5_reduce)
        Layer4h_Convolution_Inception3x3_pad = F.pad(Layer4h_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4h_Convolution_Inception3x3 = self.Layer4h_Convolution_Inception3x3(Layer4h_Convolution_Inception3x3_pad)
        Layer4h_Convolution_Inception5x5_pad = F.pad(Layer4h_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4h_Convolution_Inception5x5 = self.Layer4h_Convolution_Inception5x5(Layer4h_Convolution_Inception5x5_pad)
        Layer4h_Concat_Output = torch.cat((Layer4h_Convolution_Inception3x3, Layer4h_Convolution_Inception5x5, Layer4h_Convolution_Inception_Pool_1x1), 1)
        Layer4h_Eltwise_EltWise = Layer4h_Concat_Output + Layer4h_Convolution_ResCeption1x1
        Layer4h_BatchNorm_EltWise = self.Layer4h_BatchNorm_EltWise(Layer4h_Eltwise_EltWise)
        Layer4h_ReLU_EltWise = F.relu(Layer4h_BatchNorm_EltWise)
        Loss2_Pooling_Loss = F.avg_pool2d(Layer4h_ReLU_EltWise, kernel_size=(5, 5), stride=(3, 3), padding=(0,), ceil_mode=True, count_include_pad=False)
        Layer4i_Convolution_ResCeption1x1 = self.Layer4i_Convolution_ResCeption1x1(Layer4h_ReLU_EltWise)
        Layer4i_Convolution_Inception3x3_reduce = self.Layer4i_Convolution_Inception3x3_reduce(Layer4h_ReLU_EltWise)
        Layer4i_Convolution_Inception5x5_reduce = self.Layer4i_Convolution_Inception5x5_reduce(Layer4h_ReLU_EltWise)
        Layer4i_Pooling_Inception_Pool_pad = F.pad(Layer4h_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4i_Pooling_Inception_Pool = F.max_pool2d(Layer4i_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Loss2_Convolution_Loss = self.Loss2_Convolution_Loss(Loss2_Pooling_Loss)
        Layer4i_BatchNorm_Inception3x3_reduce = self.Layer4i_BatchNorm_Inception3x3_reduce(Layer4i_Convolution_Inception3x3_reduce)
        Layer4i_BatchNorm_Inception5x5_reduce = self.Layer4i_BatchNorm_Inception5x5_reduce(Layer4i_Convolution_Inception5x5_reduce)
        Layer4i_Convolution_Inception_Pool_1x1 = self.Layer4i_Convolution_Inception_Pool_1x1(Layer4i_Pooling_Inception_Pool)
        Loss2_BatchNorm_Loss = self.Loss2_BatchNorm_Loss(Loss2_Convolution_Loss)
        Layer4i_ReLU_Inception3x3_reduce = F.relu(Layer4i_BatchNorm_Inception3x3_reduce)
        Layer4i_ReLU_Inception5x5_reduce = F.relu(Layer4i_BatchNorm_Inception5x5_reduce)
        Loss2_ReLU_Loss = F.relu(Loss2_BatchNorm_Loss)
        Layer4i_Convolution_Inception3x3_pad = F.pad(Layer4i_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4i_Convolution_Inception3x3 = self.Layer4i_Convolution_Inception3x3(Layer4i_Convolution_Inception3x3_pad)
        Layer4i_Convolution_Inception5x5_pad = F.pad(Layer4i_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4i_Convolution_Inception5x5 = self.Layer4i_Convolution_Inception5x5(Layer4i_Convolution_Inception5x5_pad)
        Loss2_InnerProduct_Loss_fc1_0 = Loss2_ReLU_Loss.view(Loss2_ReLU_Loss.size(0), -1)
        Layer4i_Concat_Output = torch.cat((Layer4i_Convolution_Inception3x3, Layer4i_Convolution_Inception5x5, Layer4i_Convolution_Inception_Pool_1x1), 1)
        Loss2_InnerProduct_Loss_fc1_1 = self.Loss2_InnerProduct_Loss_fc1_1(Loss2_InnerProduct_Loss_fc1_0)
        Layer4i_Eltwise_EltWise = Layer4i_Concat_Output + Layer4i_Convolution_ResCeption1x1
        Loss2_BatchNorm_Loss_fc1 = self.Loss2_BatchNorm_Loss_fc1(Loss2_InnerProduct_Loss_fc1_1)
        Layer4i_BatchNorm_EltWise = self.Layer4i_BatchNorm_EltWise(Layer4i_Eltwise_EltWise)
        Loss2_ReLU_Loss_fc1 = F.relu(Loss2_BatchNorm_Loss_fc1)
        Layer4i_ReLU_EltWise = F.relu(Layer4i_BatchNorm_EltWise)
        Loss2_InnerProduct_Loss_fc2_0 = Loss2_ReLU_Loss_fc1.view(Loss2_ReLU_Loss_fc1.size(0), -1)
        Layer4j_Convolution_ResCeption1x1 = self.Layer4j_Convolution_ResCeption1x1(Layer4i_ReLU_EltWise)
        Layer4j_Convolution_Inception3x3_reduce = self.Layer4j_Convolution_Inception3x3_reduce(Layer4i_ReLU_EltWise)
        Layer4j_Convolution_Inception5x5_reduce = self.Layer4j_Convolution_Inception5x5_reduce(Layer4i_ReLU_EltWise)
        Layer4j_Pooling_Inception_Pool_pad = F.pad(Layer4i_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer4j_Pooling_Inception_Pool = F.max_pool2d(Layer4j_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Loss2_InnerProduct_Loss_fc2_1 = self.Loss2_InnerProduct_Loss_fc2_1(Loss2_InnerProduct_Loss_fc2_0)
        Layer4j_BatchNorm_Inception3x3_reduce = self.Layer4j_BatchNorm_Inception3x3_reduce(Layer4j_Convolution_Inception3x3_reduce)
        Layer4j_BatchNorm_Inception5x5_reduce = self.Layer4j_BatchNorm_Inception5x5_reduce(Layer4j_Convolution_Inception5x5_reduce)
        Layer4j_Convolution_Inception_Pool_1x1 = self.Layer4j_Convolution_Inception_Pool_1x1(Layer4j_Pooling_Inception_Pool)
        Layer4j_ReLU_Inception3x3_reduce = F.relu(Layer4j_BatchNorm_Inception3x3_reduce)
        Layer4j_ReLU_Inception5x5_reduce = F.relu(Layer4j_BatchNorm_Inception5x5_reduce)
        Layer4j_Convolution_Inception3x3_pad = F.pad(Layer4j_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer4j_Convolution_Inception3x3 = self.Layer4j_Convolution_Inception3x3(Layer4j_Convolution_Inception3x3_pad)
        Layer4j_Convolution_Inception5x5_pad = F.pad(Layer4j_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer4j_Convolution_Inception5x5 = self.Layer4j_Convolution_Inception5x5(Layer4j_Convolution_Inception5x5_pad)
        Layer4j_Concat_Output = torch.cat((Layer4j_Convolution_Inception3x3, Layer4j_Convolution_Inception5x5, Layer4j_Convolution_Inception_Pool_1x1), 1)
        Layer4j_Eltwise_EltWise = Layer4j_Concat_Output + Layer4j_Convolution_ResCeption1x1
        Layer4j_BatchNorm_EltWise = self.Layer4j_BatchNorm_EltWise(Layer4j_Eltwise_EltWise)
        Layer4j_ReLU_EltWise = F.relu(Layer4j_BatchNorm_EltWise)
        Layer4_Pooling_Pooling_Stride_2_pad = F.pad(Layer4j_ReLU_EltWise, (0, 1, 0, 1), value=float('-inf'))
        Layer4_Pooling_Pooling_Stride_2 = F.max_pool2d(Layer4_Pooling_Pooling_Stride_2_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False)
        Layer5a_Convolution_ResCeption1x1 = self.Layer5a_Convolution_ResCeption1x1(Layer4_Pooling_Pooling_Stride_2)
        Layer5a_Convolution_Inception3x3_reduce = self.Layer5a_Convolution_Inception3x3_reduce(Layer4_Pooling_Pooling_Stride_2)
        Layer5a_Convolution_Inception5x5_reduce = self.Layer5a_Convolution_Inception5x5_reduce(Layer4_Pooling_Pooling_Stride_2)
        Layer5a_Pooling_Inception_Pool_pad = F.pad(Layer4_Pooling_Pooling_Stride_2, (1, 1, 1, 1), value=float('-inf'))
        Layer5a_Pooling_Inception_Pool = F.max_pool2d(Layer5a_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer5a_BatchNorm_Inception3x3_reduce = self.Layer5a_BatchNorm_Inception3x3_reduce(Layer5a_Convolution_Inception3x3_reduce)
        Layer5a_BatchNorm_Inception5x5_reduce = self.Layer5a_BatchNorm_Inception5x5_reduce(Layer5a_Convolution_Inception5x5_reduce)
        Layer5a_Convolution_Inception_Pool_1x1 = self.Layer5a_Convolution_Inception_Pool_1x1(Layer5a_Pooling_Inception_Pool)
        Layer5a_ReLU_Inception3x3_reduce = F.relu(Layer5a_BatchNorm_Inception3x3_reduce)
        Layer5a_ReLU_Inception5x5_reduce = F.relu(Layer5a_BatchNorm_Inception5x5_reduce)
        Layer5a_Convolution_Inception3x3_pad = F.pad(Layer5a_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer5a_Convolution_Inception3x3 = self.Layer5a_Convolution_Inception3x3(Layer5a_Convolution_Inception3x3_pad)
        Layer5a_Convolution_Inception5x5_pad = F.pad(Layer5a_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer5a_Convolution_Inception5x5 = self.Layer5a_Convolution_Inception5x5(Layer5a_Convolution_Inception5x5_pad)
        Layer5a_Concat_Output = torch.cat((Layer5a_Convolution_Inception3x3, Layer5a_Convolution_Inception5x5, Layer5a_Convolution_Inception_Pool_1x1), 1)
        Layer5a_Eltwise_EltWise = Layer5a_Concat_Output + Layer5a_Convolution_ResCeption1x1
        Layer5a_BatchNorm_EltWise = self.Layer5a_BatchNorm_EltWise(Layer5a_Eltwise_EltWise)
        Layer5a_ReLU_EltWise = F.relu(Layer5a_BatchNorm_EltWise)
        Layer5b_Convolution_ResCeption1x1 = self.Layer5b_Convolution_ResCeption1x1(Layer5a_ReLU_EltWise)
        Layer5b_Convolution_Inception3x3_reduce = self.Layer5b_Convolution_Inception3x3_reduce(Layer5a_ReLU_EltWise)
        Layer5b_Convolution_Inception5x5_reduce = self.Layer5b_Convolution_Inception5x5_reduce(Layer5a_ReLU_EltWise)
        Layer5b_Pooling_Inception_Pool_pad = F.pad(Layer5a_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer5b_Pooling_Inception_Pool = F.max_pool2d(Layer5b_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer5b_BatchNorm_Inception3x3_reduce = self.Layer5b_BatchNorm_Inception3x3_reduce(Layer5b_Convolution_Inception3x3_reduce)
        Layer5b_BatchNorm_Inception5x5_reduce = self.Layer5b_BatchNorm_Inception5x5_reduce(Layer5b_Convolution_Inception5x5_reduce)
        Layer5b_Convolution_Inception_Pool_1x1 = self.Layer5b_Convolution_Inception_Pool_1x1(Layer5b_Pooling_Inception_Pool)
        Layer5b_ReLU_Inception3x3_reduce = F.relu(Layer5b_BatchNorm_Inception3x3_reduce)
        Layer5b_ReLU_Inception5x5_reduce = F.relu(Layer5b_BatchNorm_Inception5x5_reduce)
        Layer5b_Convolution_Inception3x3_pad = F.pad(Layer5b_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer5b_Convolution_Inception3x3 = self.Layer5b_Convolution_Inception3x3(Layer5b_Convolution_Inception3x3_pad)
        Layer5b_Convolution_Inception5x5_pad = F.pad(Layer5b_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer5b_Convolution_Inception5x5 = self.Layer5b_Convolution_Inception5x5(Layer5b_Convolution_Inception5x5_pad)
        Layer5b_Concat_Output = torch.cat((Layer5b_Convolution_Inception3x3, Layer5b_Convolution_Inception5x5, Layer5b_Convolution_Inception_Pool_1x1), 1)
        Layer5b_Eltwise_EltWise = Layer5b_Concat_Output + Layer5b_Convolution_ResCeption1x1
        Layer5b_BatchNorm_EltWise = self.Layer5b_BatchNorm_EltWise(Layer5b_Eltwise_EltWise)
        Layer5b_ReLU_EltWise = F.relu(Layer5b_BatchNorm_EltWise)
        Layer5c_Convolution_ResCeption1x1 = self.Layer5c_Convolution_ResCeption1x1(Layer5b_ReLU_EltWise)
        Layer5c_Convolution_Inception3x3_reduce = self.Layer5c_Convolution_Inception3x3_reduce(Layer5b_ReLU_EltWise)
        Layer5c_Convolution_Inception5x5_reduce = self.Layer5c_Convolution_Inception5x5_reduce(Layer5b_ReLU_EltWise)
        Layer5c_Pooling_Inception_Pool_pad = F.pad(Layer5b_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer5c_Pooling_Inception_Pool = F.max_pool2d(Layer5c_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer5c_BatchNorm_Inception3x3_reduce = self.Layer5c_BatchNorm_Inception3x3_reduce(Layer5c_Convolution_Inception3x3_reduce)
        Layer5c_BatchNorm_Inception5x5_reduce = self.Layer5c_BatchNorm_Inception5x5_reduce(Layer5c_Convolution_Inception5x5_reduce)
        Layer5c_Convolution_Inception_Pool_1x1 = self.Layer5c_Convolution_Inception_Pool_1x1(Layer5c_Pooling_Inception_Pool)
        Layer5c_ReLU_Inception3x3_reduce = F.relu(Layer5c_BatchNorm_Inception3x3_reduce)
        Layer5c_ReLU_Inception5x5_reduce = F.relu(Layer5c_BatchNorm_Inception5x5_reduce)
        Layer5c_Convolution_Inception3x3_pad = F.pad(Layer5c_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer5c_Convolution_Inception3x3 = self.Layer5c_Convolution_Inception3x3(Layer5c_Convolution_Inception3x3_pad)
        Layer5c_Convolution_Inception5x5_pad = F.pad(Layer5c_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer5c_Convolution_Inception5x5 = self.Layer5c_Convolution_Inception5x5(Layer5c_Convolution_Inception5x5_pad)
        Layer5c_Concat_Output = torch.cat((Layer5c_Convolution_Inception3x3, Layer5c_Convolution_Inception5x5, Layer5c_Convolution_Inception_Pool_1x1), 1)
        Layer5c_Eltwise_EltWise = Layer5c_Concat_Output + Layer5c_Convolution_ResCeption1x1
        Layer5c_BatchNorm_EltWise = self.Layer5c_BatchNorm_EltWise(Layer5c_Eltwise_EltWise)
        Layer5c_ReLU_EltWise = F.relu(Layer5c_BatchNorm_EltWise)
        Layer5d_Convolution_ResCeption1x1 = self.Layer5d_Convolution_ResCeption1x1(Layer5c_ReLU_EltWise)
        Layer5d_Convolution_Inception3x3_reduce = self.Layer5d_Convolution_Inception3x3_reduce(Layer5c_ReLU_EltWise)
        Layer5d_Convolution_Inception5x5_reduce = self.Layer5d_Convolution_Inception5x5_reduce(Layer5c_ReLU_EltWise)
        Layer5d_Pooling_Inception_Pool_pad = F.pad(Layer5c_ReLU_EltWise, (1, 1, 1, 1), value=float('-inf'))
        Layer5d_Pooling_Inception_Pool = F.max_pool2d(Layer5d_Pooling_Inception_Pool_pad, kernel_size=(3, 3), stride=(1, 1), padding=0, ceil_mode=False)
        Layer5d_BatchNorm_Inception3x3_reduce = self.Layer5d_BatchNorm_Inception3x3_reduce(Layer5d_Convolution_Inception3x3_reduce)
        Layer5d_BatchNorm_Inception5x5_reduce = self.Layer5d_BatchNorm_Inception5x5_reduce(Layer5d_Convolution_Inception5x5_reduce)
        Layer5d_Convolution_Inception_Pool_1x1 = self.Layer5d_Convolution_Inception_Pool_1x1(Layer5d_Pooling_Inception_Pool)
        Layer5d_ReLU_Inception3x3_reduce = F.relu(Layer5d_BatchNorm_Inception3x3_reduce)
        Layer5d_ReLU_Inception5x5_reduce = F.relu(Layer5d_BatchNorm_Inception5x5_reduce)
        Layer5d_Convolution_Inception3x3_pad = F.pad(Layer5d_ReLU_Inception3x3_reduce, (1, 1, 1, 1))
        Layer5d_Convolution_Inception3x3 = self.Layer5d_Convolution_Inception3x3(Layer5d_Convolution_Inception3x3_pad)
        Layer5d_Convolution_Inception5x5_pad = F.pad(Layer5d_ReLU_Inception5x5_reduce, (2, 2, 2, 2))
        Layer5d_Convolution_Inception5x5 = self.Layer5d_Convolution_Inception5x5(Layer5d_Convolution_Inception5x5_pad)
        Layer5d_Concat_Output = torch.cat((Layer5d_Convolution_Inception3x3, Layer5d_Convolution_Inception5x5, Layer5d_Convolution_Inception_Pool_1x1), 1)
        Layer5d_Eltwise_EltWise = Layer5d_Concat_Output + Layer5d_Convolution_ResCeption1x1
        Layer5d_BatchNorm_EltWise = self.Layer5d_BatchNorm_EltWise(Layer5d_Eltwise_EltWise)
        Layer5d_ReLU_EltWise = F.relu(Layer5d_BatchNorm_EltWise)
        Loss3_Pooling_Loss = F.avg_pool2d(Layer5d_ReLU_EltWise, kernel_size=(7, 7), stride=(1, 1), padding=(0,), ceil_mode=False, count_include_pad=False)
        Loss3_InnerProduct_Loss_fc1_0 = Loss3_Pooling_Loss.view(Loss3_Pooling_Loss.size(0), -1)
        Loss3_InnerProduct_Loss_fc1_1 = self.Loss3_InnerProduct_Loss_fc1_1(Loss3_InnerProduct_Loss_fc1_0)
        prob            = F.softmax(Loss3_InnerProduct_Loss_fc1_1)
        return Loss1_InnerProduct_Loss_fc2_1, Loss2_InnerProduct_Loss_fc2_1, prob


    @staticmethod
    def __batch_normalization(dim, name, **kwargs):
        if   dim == 0 or dim == 1:  layer = nn.BatchNorm1d(**kwargs)
        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)
        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)
        else:           raise NotImplementedError()

        if 'scale' in __weights_dict[name]:
            layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['scale']))
        else:
            layer.weight.data.fill_(1)

        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        else:
            layer.bias.data.fill_(0)

        layer.state_dict()['running_mean'].copy_(torch.from_numpy(__weights_dict[name]['mean']))
        layer.state_dict()['running_var'].copy_(torch.from_numpy(__weights_dict[name]['var']))
        return layer

    @staticmethod
    def __dense(name, **kwargs):
        layer = nn.Linear(**kwargs)
        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))
        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        return layer

    @staticmethod
    def __conv(dim, name, **kwargs):
        if   dim == 1:  layer = nn.Conv1d(**kwargs)
        elif dim == 2:  layer = nn.Conv2d(**kwargs)
        elif dim == 3:  layer = nn.Conv3d(**kwargs)
        else:           raise NotImplementedError()

        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))
        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        return layer

